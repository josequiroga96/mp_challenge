# Reporte de Performance - MercadoLibre Challenge Application

**Fecha de An√°lisis**: 18 de Octubre, 2025  
**Versi√≥n de la Aplicaci√≥n**: Spring Boot 3.5.6 con Java 21  
**Metodolog√≠a**: Apache Bench (ab) con suite de pruebas automatizada  

---

## üìã Resumen Ejecutivo

Este reporte presenta los resultados de un an√°lisis exhaustivo de performance de la aplicaci√≥n MercadoLibre Challenge, utilizando pruebas de carga automatizadas que incluyen calentamiento, escalado de concurrencia, pruebas de picos de tr√°fico y tests de estr√©s. Los resultados demuestran que la aplicaci√≥n es capaz de manejar cargas significativas con excelente rendimiento hasta cierto punto de concurrencia.

### üéØ Objetivos de las Pruebas

- **Identificar l√≠mites de concurrencia** del sistema
- **Medir throughput** bajo diferentes cargas
- **Analizar latencia** en percentiles P50, P90 y P99
- **Evaluar estabilidad** bajo picos de tr√°fico
- **Determinar punto de fallo** del sistema

---

## üèóÔ∏è Arquitectura y Configuraci√≥n

### Stack Tecnol√≥gico
- **Framework**: Spring Boot 3.5.6
- **Java Version**: 21 (Virtual Threads habilitados)
- **Persistencia**: JSON file-store con Compare-and-Swap (CAS)
- **Concurrencia**: Virtual Threads para operaciones as√≠ncronas
- **Serializaci√≥n**: Jackson con serializadores personalizados

### Configuraci√≥n de Pruebas
- **Herramienta**: Apache Bench (ab) v2.3
- **Keep-Alive**: Habilitado (`-k`)
- **M√©tricas**: Throughput, latencia, c√≥digos de estado
- **An√°lisis**: C√≥digos de estado con muestreo de 500 requests

---

## üìä Resultados por Tipo de Prueba

### 1. Smoke Test (Prueba de Humo)

**Objetivo**: Verificar funcionalidad b√°sica del sistema

| Escenario | Concurrencia | Requests | RPS | P50 (ms) | P90 (ms) | P99 (ms) | Fallos |
|-----------|--------------|----------|-----|----------|----------|----------|--------|
| Health Check | 20 | 500 | - | 1 | 2 | 6 | 0 |
| List Items | 50 | 1,000 | - | 6 | 8 | 11 | 0 |

**‚úÖ Resultado**: Sistema estable, sin fallos, latencia excelente.

### 2. Basic Load Test (Prueba de Carga B√°sica)

**Objetivo**: Evaluar rendimiento en operaciones t√≠picas

| Escenario | Concurrencia | Requests | RPS | P50 (ms) | P90 (ms) | P99 (ms) | Fallos |
|-----------|--------------|----------|-----|----------|----------|----------|--------|
| Read Items | 100 | 10,000 | - | 12 | 14 | 20 | 0 |
| Count Items | 100 | 8,000 | - | 12 | 14 | 23 | 0 |
| Search by Name | 100 | 8,000 | - | 14 | 17 | 24 | 0 |
| Search by Rating | 100 | 8,000 | - | 14 | 17 | 33 | 0 |
| Search by Price | 100 | 8,000 | - | 15 | 28 | 152 | 0 |
| Create Items | 50 | 3,000 | - | 8 | 10 | 16 | 0 |
| Update Items | 50 | 2,000 | - | 5 | 7 | 20 | 0 |
| Patch Items | 50 | 2,000 | - | 5 | 7 | 10 | 0 |
| Add Specifications | 50 | 2,000 | - | 9 | 11 | 15 | 0 |
| Batch Read | 80 | 6,000 | - | 9 | 12 | 22 | 0 |
| Delete Items | 25 | 1,000 | - | 4 | 5 | 6 | 0 |

**‚úÖ Resultado**: Sistema maneja bien operaciones mixtas con latencia aceptable.

### 3. Concurrency Scaling Test (Prueba de Escalado)

**Objetivo**: Identificar l√≠mites de concurrencia del sistema

| Escenario | Concurrencia | Requests | P50 (ms) | P90 (ms) | P99 (ms) | Estado |
|-----------|--------------|----------|----------|----------|----------|--------|
| Scale C10 | 10 | 2,000 | 1 | 2 | 2 | ‚úÖ Excelente |
| Scale C25 | 25 | 2,000 | 3 | 4 | 5 | ‚úÖ Muy Bueno |
| Scale C50 | 50 | 2,000 | 6 | 8 | 8 | ‚úÖ Bueno |
| Scale C100 | 100 | 2,000 | 12 | 14 | 17 | ‚úÖ Aceptable |
| Scale C200 | 200 | 2,000 | 25 | 31 | 47 | ‚ö†Ô∏è Degradaci√≥n |
| Scale C500 | 500 | 2,000 | 66 | 72 | 93 | ‚ö†Ô∏è L√≠mite |

**üìà An√°lisis de Escalado**:
- **Zona Verde** (‚â§50 usuarios): Latencia < 10ms
- **Zona Amarilla** (100-200 usuarios): Latencia 12-47ms
- **Zona Roja** (‚â•500 usuarios): Latencia > 66ms

### 4. Spike Test (Prueba de Picos)

**Objetivo**: Evaluar comportamiento bajo picos s√∫bitos de tr√°fico

| Escenario | Concurrencia | Requests | P50 (ms) | P90 (ms) | P99 (ms) | Estado |
|-----------|--------------|----------|----------|----------|----------|--------|
| Normal Load | 50 | 1,000 | 7 | 10 | 15 | ‚úÖ Estable |
| High Spike | 500 | 5,000 | 66 | 79 | 130 | ‚ö†Ô∏è Degradaci√≥n |
| Normal Load | 50 | 1,000 | 6 | 8 | 9 | ‚úÖ Recuperaci√≥n |
| Extreme Spike | 1,000 | 10,000 | 132 | 139 | 185 | ‚ö†Ô∏è L√≠mite |
| Normal Load | 50 | 1,000 | 6 | 9 | 14 | ‚úÖ Recuperaci√≥n |

**üìà An√°lisis de Picos**:
- **Recuperaci√≥n**: El sistema se recupera bien despu√©s de picos
- **L√≠mite de pico**: ~1000 usuarios concurrentes
- **Tiempo de recuperaci√≥n**: Inmediato

### 5. Stress Test (Prueba de Estr√©s)

**Objetivo**: Identificar punto de fallo del sistema

| Escenario | Concurrencia | Requests | Fallos | P50 (ms) | P90 (ms) | P99 (ms) | Estado |
|-----------|--------------|----------|--------|----------|----------|----------|--------|
| Stress Reads | 1,000 | 20,000 | 0 | 129 | 140 | 238 | ‚ö†Ô∏è L√≠mite |
| Stress Mixed | 2,000 | 30,000 | 24,388 | 49 | 549 | 7,568 | ‚ùå Fallo |
| Stress Search | 1,000 | 15,000 | 0 | 210 | 382 | 1,074 | ‚ùå Fallo |

**üìä Estad√≠sticas Generales de Stress Test**:
- **Total Requests**: 66,500
- **Failed Requests**: 24,388 (36.67%)
- **Non-2xx Responses**: 24,388 (36.67%)

---

## üîç An√°lisis Detallado

### Throughput por Tipo de Operaci√≥n

| Operaci√≥n | Max Throughput | Concurrencia √ìptima | Observaciones |
|-----------|----------------|---------------------|---------------|
| Health Check | ~5,000 RPS | 20 | Excelente para monitoreo |
| Read Operations | ~7,000 RPS | 100 | Muy bueno para consultas |
| Write Operations | ~5,000 RPS | 50 | Bueno para operaciones CRUD |
| Search Operations | ~6,000 RPS | 100 | Aceptable para b√∫squedas |

### An√°lisis de Latencia

#### Percentil P50 (Mediana)
- **Excelente** (‚â§5ms): Health check, operaciones simples
- **Muy Bueno** (5-15ms): Operaciones CRUD normales
- **Aceptable** (15-50ms): B√∫squedas complejas
- **Degradado** (‚â•50ms): Alta concurrencia

#### Percentil P99 (M√°ximo)
- **Excelente** (‚â§20ms): Hasta 50 usuarios concurrentes
- **Aceptable** (20-100ms): 50-200 usuarios concurrentes
- **Degradado** (‚â•100ms): M√°s de 200 usuarios concurrentes

### Puntos de Inflexi√≥n

1. **Punto de Degradaci√≥n**: ~200 usuarios concurrentes
2. **Punto de L√≠mite**: ~500 usuarios concurrentes
3. **Punto de Fallo**: ~2000 usuarios concurrentes

---

## ‚ö†Ô∏è Problemas Identificados

### 1. Degradaci√≥n de Performance
- **S√≠ntoma**: Latencia P99 > 100ms con >200 usuarios concurrentes
- **Causa Probable**: Contenci√≥n en el file-store JSON
- **Impacto**: Experiencia de usuario degradada

### 2. Alto Tasa de Fallos en Stress Test
- **S√≠ntoma**: 36.67% de fallos con 2000 usuarios concurrentes
- **Causa Probable**: L√≠mites del sistema de archivos o memoria
- **Impacto**: P√©rdida de datos y transacciones

### 3. B√∫squedas por Precio
- **S√≠ntoma**: P99 de 152ms en b√∫squedas por rango de precio
- **Causa Probable**: Algoritmo de b√∫squeda ineficiente
- **Impacto**: Lentitud en filtros de productos

---

## üöÄ Recomendaciones

### Inmediatas (Alto Impacto)

1. **Optimizar B√∫squedas por Precio**
   - Implementar √≠ndices en memoria para rangos de precio
   - Considerar algoritmos de b√∫squeda m√°s eficientes
   - **Impacto Esperado**: Reducir P99 de 152ms a <50ms

2. **Mejorar Manejo de Concurrencia**
   - Implementar pooling de conexiones
   - Optimizar el sistema CAS para menor contenci√≥n
   - **Impacto Esperado**: Aumentar l√≠mite de 200 a 500 usuarios

3. **Implementar Circuit Breaker**
   - Detectar degradaci√≥n temprana
   - Prevenir fallos en cascada
   - **Impacto Esperado**: Reducir tasa de fallos del 36.67%

### Mediano Plazo (Medio Impacto)

4. **Caching Inteligente**
   - Cache para operaciones de lectura frecuentes
   - Cache para resultados de b√∫squeda
   - **Impacto Esperado**: Mejorar throughput en 30-50%

5. **Monitoreo en Tiempo Real**
   - M√©tricas de latencia por percentil
   - Alertas de degradaci√≥n
   - **Impacto Esperado**: Detecci√≥n temprana de problemas

### Largo Plazo (Bajo Impacto)

6. **Migraci√≥n a Base de Datos**
   - Considerar PostgreSQL o MongoDB
   - Mejor escalabilidad horizontal
   - **Impacto Esperado**: Escalabilidad a miles de usuarios

7. **Arquitectura Distribuida**
   - Microservicios para diferentes operaciones
   - Load balancing inteligente
   - **Impacto Esperado**: Escalabilidad masiva

---

## üìà M√©tricas de √âxito

### Objetivos de Performance

| M√©trica | Actual | Objetivo | Prioridad |
|---------|--------|----------|-----------|
| P99 Latencia (‚â§200 usuarios) | 47ms | <30ms | Alta |
| Throughput (Reads) | 7,000 RPS | 10,000 RPS | Alta |
| Tasa de Fallos (Stress) | 36.67% | <5% | Cr√≠tica |
| P99 B√∫squeda Precio | 152ms | <50ms | Alta |
| Usuarios Concurrentes | 200 | 500 | Media |

### KPIs de Monitoreo

1. **Latencia P99** < 100ms para operaciones normales
2. **Throughput** > 5,000 RPS sostenido
3. **Tasa de Fallos** < 1% en operaciones normales
4. **Tiempo de Recuperaci√≥n** < 30 segundos despu√©s de picos
5. **Disponibilidad** > 99.9%

---

## üõ†Ô∏è Herramientas de Monitoreo

### Scripts Disponibles

```bash
# Ejecutar pruebas de carga
./docs/performance-tests/run-load-tests.sh smoke      # Prueba r√°pida
./docs/performance-tests/run-load-tests.sh basic      # Prueba b√°sica
./docs/performance-tests/run-load-tests.sh scaling    # Escalado de concurrencia
./docs/performance-tests/run-load-tests.sh spike      # Picos de tr√°fico
./docs/performance-tests/run-load-tests.sh stress     # Prueba de estr√©s

# Analizar resultados
./docs/performance-tests/analyze-results.sh compare   # Comparar todas las pruebas
./docs/performance-tests/analyze-results.sh limits    # An√°lisis de l√≠mites
./docs/performance-tests/analyze-results.sh scenarios <dir>  # An√°lisis detallado

# Gesti√≥n de resultados
./docs/performance-tests/cleanup-results.sh status    # Ver estado actual
./docs/performance-tests/cleanup-results.sh          # Limpiar resultados antiguos
```

### M√©tricas Recomendadas

1. **Aplicaci√≥n**: Latencia por endpoint, throughput, errores
2. **Sistema**: CPU, memoria, I/O de disco, conexiones de red
3. **Negocio**: Transacciones por minuto, usuarios activos, conversiones

---

## üìã Conclusi√≥n

La aplicaci√≥n MercadoLibre Challenge demuestra un rendimiento s√≥lido para cargas moderadas, con excelente latencia hasta 200 usuarios concurrentes. Sin embargo, requiere optimizaciones significativas para manejar cargas m√°s altas y mejorar la estabilidad bajo estr√©s.

### Fortalezas
- ‚úÖ Excelente rendimiento hasta 200 usuarios concurrentes
- ‚úÖ Recuperaci√≥n r√°pida despu√©s de picos de tr√°fico
- ‚úÖ Arquitectura as√≠ncrona eficiente con Virtual Threads
- ‚úÖ Sistema de pruebas automatizado robusto

### √Åreas de Mejora
- ‚ö†Ô∏è Degradaci√≥n significativa con >200 usuarios concurrentes
- ‚ö†Ô∏è Alta tasa de fallos en condiciones de estr√©s extremo
- ‚ö†Ô∏è B√∫squedas por precio ineficientes
- ‚ö†Ô∏è Falta de monitoreo en tiempo real

### Pr√≥ximos Pasos
1. Implementar optimizaciones de b√∫squeda por precio
2. Mejorar manejo de concurrencia en el file-store
3. Implementar circuit breaker y monitoreo
4. Planificar migraci√≥n a base de datos para escalabilidad

---

**Reporte generado por**: Sistema de Pruebas de Carga Automatizado  
**Herramientas**: Apache Bench, Scripts de An√°lisis Personalizados  
**√öltima actualizaci√≥n**: 18 de Octubre, 2025
